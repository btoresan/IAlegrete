{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g5GN3EpDn4b"
      },
      "source": [
        "\n",
        "Imports e definição do dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gpxhsZya71hk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-15 19:14:58.650069: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-15 19:15:00.852133: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:920] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2025-04-15 19:15:02.905581: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:920] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2025-04-15 19:15:02.905639: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:920] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configura tensorflow para não alocar toda a memória da GPU automaticamente\n",
        "# Evita travamentos no sistema, se executando em GPU\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQhkJUZODtd1"
      },
      "source": [
        "Carregamento do dataset cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQQvrT5v785X"
      },
      "outputs": [],
      "source": [
        "# Carregar o conjunto de dados CIFAR-10\n",
        "cifar10 = keras.datasets.cifar10\n",
        "#Carrega duas tuplas, representando os dados de treinamento e de teste.\n",
        "#Cada tupla tem as imagens e os respectivos rótulos\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwHzFJajDxZt"
      },
      "source": [
        "O código abaixo mostra as 10 primeiras imagens de treino e teste do cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJipJNqX9zsJ"
      },
      "outputs": [],
      "source": [
        "# Defina as classes do CIFAR-10\n",
        "class_names = ['Avião', 'Automóvel', 'Pássaro', 'Gato', 'Cervo',\n",
        "               'Cachorro', 'Sapo', 'Cavalo', 'Navio', 'Caminhão']\n",
        "\n",
        "# Crie um dicionário para mapear as classes para as imagens correspondentes\n",
        "class_to_image = {}\n",
        "for i in range(10):\n",
        "    index = (test_labels == i).nonzero()[0][0]  # Encontre o primeiro índice da classe\n",
        "    class_to_image[i] = test_images[index]\n",
        "\n",
        "# Mostre uma imagem de cada classe\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.xticks([])  # Remova os rótulos do eixo x\n",
        "    plt.yticks([])  # Remova os rótulos do eixo y\n",
        "    plt.imshow(class_to_image[i])\n",
        "    plt.xlabel(class_names[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZxLXNIaD4lq"
      },
      "source": [
        "Abaixo, convertemos os rótulos escalares (números de 0 a 9) para one-hot encoding.\n",
        "\n",
        "Não é necessário realizar este passo, caso seja utilizada a função de custo esparse_categorical_cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h1CJgPJ9MTt"
      },
      "outputs": [],
      "source": [
        "# Converter para codificação one-hot dos labels\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "#Não é necessário se utilizar como função de custo esparse_categorical_cross_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nymnOpRMETAu"
      },
      "source": [
        "Função que retorna uma rede neural para o cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPrIRBmT8XiN"
      },
      "outputs": [],
      "source": [
        "# Crie o modelo de rede neural convolucional simples\n",
        "def get_cifar10_network():\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),#(32, 32, 3) porque as imagens são 32X32 e RGB, portanto, tendo 3 canais de cor\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')  # 10 classes de saída\n",
        "    ])\n",
        "\n",
        "    # Compile o modelo\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',#pode ser substituída pela esparse_categorical_cross_entropy\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjmscwcQErIx"
      },
      "source": [
        "Trecho para treinar e avaliar a rede neural.\n",
        "O treino é realizado com os dados de treino e a avaliação do modelo é realizada nos dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uN8v8_m8cvR"
      },
      "outputs": [],
      "source": [
        "# Refatoramos o código para facilitar o treinamento e avaliação de todos os modelos\n",
        "import time\n",
        "\n",
        "# Treina o modelo\n",
        "def train(model, train_images, train_labels, epochs=10):\n",
        "    start = time.time()\n",
        "    model.fit(train_images, train_labels, epochs=epochs)\n",
        "    print('Tempo de treinamento:', time.time() - start)\n",
        "\n",
        "# Avalia o modelo\n",
        "def eval(model, test_images, test_labels):\n",
        "    test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "    print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# model = get_cifar10_network()\n",
        "# train(model, cifar10_train_images, cifar10_train_labels)\n",
        "# eval(model, cifar10_test_images, cifar10_test_labels)\n",
        "\n",
        "model = get_cifar100_network()\n",
        "train(model, cifar100_train_images, cifar100_train_labels)\n",
        "eval(model, cifar100_test_images, cifar100_test_labels)\n",
        "\n",
        "# model = get_mnist_network()\n",
        "# train(model, mnist_train_images, mnist_train_labels)\n",
        "# eval(model, mnist_test_images, mnist_test_labels)\n",
        "\n",
        "# model = get_fashion_mnist_network()\n",
        "# train(model, fmnist_train_images, fmnist_train_labels)\n",
        "# eval(model, fmnist_test_images, fmnist_test_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc5-m031HdY0"
      },
      "source": [
        "Na célula abaixo, adicione o código para carregar os demais datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ6iW7spLOsb"
      },
      "outputs": [],
      "source": [
        "# Carregar o conjunto de dados MNIST\n",
        "mnist = keras.datasets.mnist\n",
        "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = mnist.load_data()\n",
        "mnist_num_classes = 10\n",
        "\n",
        "# Carregar o conjunto de dados Fashion MNIST\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(fmnist_train_images, fmnist_train_labels), (fmnist_test_images, fmnist_test_labels) = fashion_mnist.load_data()\n",
        "fashion_mnist_num_classes = 10\n",
        "\n",
        "# Carregar o conjunto de dados CIFAR-10\n",
        "cifar10 = keras.datasets.cifar10\n",
        "(cifar10_train_images, cifar10_train_labels), (cifar10_test_images, cifar10_test_labels) = cifar10.load_data()\n",
        "cifar10_num_classes = 10\n",
        "\n",
        "# Carregar o conjunto de dados CIFAR-100\n",
        "cifar100 = keras.datasets.cifar100\n",
        "(cifar100_train_images, cifar100_train_labels), (cifar100_test_images, cifar100_test_labels) = cifar100.load_data(label_mode='fine')\n",
        "cifar100_num_classes = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKkBlEy1ExHj"
      },
      "source": [
        "Tarefa\n",
        "Escreva código para executar redes neurais nos seguintes datasets:\n",
        "\n",
        "MNIST (pode aproveitar o codigo existente)\n",
        "Fashion MNIST\n",
        "CIFAR-10\n",
        "CIFAR-100\n",
        "Cada execução deve ser por 10 épocas.\n",
        "\n",
        "Você deve preencher as funções a seguir para retornarem a rede neural com a melhor configuração que você conseguiu para cada dataset. O notebook deve ser entregue com a rede neural que obteve a melhor performance em cada conjunto de dados.\n",
        "\n",
        "IMPORTANTE: as funções não devem TREINAR nem AVALIAR as redes neurais, apenas instanciá-las e retorná-las.\n",
        "\n",
        "Ao final, preencha o dict results com o desempenho encontrado em cada execução."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN14IpXnFfCQ"
      },
      "outputs": [],
      "source": [
        "def get_fashion_mnist_network():\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(fashion_mnist_num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_mnist_network():\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(56, activation='relu'),\n",
        "        tf.keras.layers.Dense(28, activation='relu'),\n",
        "\n",
        "        tf.keras.layers.Dense(mnist_num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_cifar100_network():\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        tf.keras.layers.Dense(cifar100_num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_cifar10_network():\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        tf.keras.layers.Dense(cifar10_num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iERVafMPF2Tn"
      },
      "source": [
        "Preencha o dict abaixo substituindo os None com a acuracia final (acc) e o tempo de treinamento (time) encontrado no seu experimento pra cada dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEUK1xk6Fk48"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    \"mnist\": {\"time\": 47.76, \"acc\": 97.43},\n",
        "    \"fashion_mnist\": {\"time\": 49.85, \"acc\": 89.34},\n",
        "    \"cifar10\": {\"time\": 65.54, \"acc\": 74.73},\n",
        "    \"cifar100\": {\"time\": 94.59, \"acc\": 53.76},\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
